{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnnT58OAN798"
      },
      "source": [
        "<h1> Churn Analysis Project </h1>\n",
        "\n",
        "This project is a proof of concept model for analyzing customer churn. Some key indicators for churn are long periods of 0 sales, consistent decreases in spending.\n",
        "\n",
        "<h2> How it works </h2>\n",
        "\n",
        "A synthetic customer dataset is created that creates random data between 1-100 for customer financial data. A percentage of the synthetic customers are assigned a churn value, indicating whether or not the attrition is likely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhQ9bm0RNCCz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import warnings\n",
        "from scipy.fftpack import fft, fftfreq\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "agr26jhtn8Bl"
      },
      "outputs": [],
      "source": [
        "def ARIMAPredict(df, order):\n",
        "  from statsmodels.tsa.arima.model import ARIMA\n",
        "  import warnings\n",
        "\n",
        "  # Suppress warnings\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "  model = ARIMA(df, order=order)  # Adjust order as needed\n",
        "  model_fit = model.fit()\n",
        "\n",
        "      # Forecast the next value\n",
        "  forecast = model_fit.forecast(steps=1)\n",
        "  print(forecast)\n",
        "  # Print the results\n",
        "  return forecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnGY-g6lO9Vz"
      },
      "source": [
        "<h1> Create Customer Churn Examples </h1>\n",
        "TODO: include fourier analysis\n",
        "include ARIMA prediction model for next month\n",
        "If the difference in forecast and true are significant (30% lower), flag the customer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "7qzS-O0ZFr0E",
        "outputId": "027683b6-6b55-488c-85c6-470fb0a1595a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select the file(s) to upload.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a1a9abe-768c-44c6-8598-1ba5160a20aa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5a1a9abe-768c-44c6-8598-1ba5160a20aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Midyear-2022.csv to Midyear-2022.csv\n",
            "Uploaded file: Midyear-2022.csv\n",
            "File saved locally as: Midyear-2022.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Code  Total Value  5/1/2022  5/2/2022   5/3/2022  \\\n",
              "1              CARDINAL AG   9795245.76      0.00  87112.55  200531.83   \n",
              "2         WESTPHAL/MADISON   9636683.97      0.00  11071.85    7058.76   \n",
              "3           FAITH/APPLETON   9263184.71      0.00  88762.71  190116.91   \n",
              "4        BW CONVERTING INC   8593581.40      0.00   6268.76   20321.95   \n",
              "5      PIEPER ELE/PEWAUKEE   7847637.88   2294.67  10599.71   28358.42   \n",
              "...                    ...          ...       ...       ...        ...   \n",
              "5396               NOVOLEX      -518.62      0.00      0.00       0.00   \n",
              "5397  WAUKESHA BEARING COR      -549.19      0.00      0.00       0.00   \n",
              "5398  MUNICIPAL FILTRATION     -1868.70      0.00      0.00       0.00   \n",
              "5399          PJ KAMPO ELE     -2471.54    948.97      0.00       0.00   \n",
              "5400                   WES   -913928.95      0.00      0.00       0.00   \n",
              "\n",
              "      5/4/2022  5/5/2022  5/6/2022  5/7/2022  5/8/2022  ...  4/21/2023  \\\n",
              "1     46674.44  25938.74  14902.59      0.00      0.00  ...   15143.89   \n",
              "2     15032.52  33767.46  32518.26      0.00      0.00  ...   42934.36   \n",
              "3      8995.34   5552.67  22690.98      0.00      0.00  ...   42187.62   \n",
              "4     24138.10  63070.01  25113.64      0.00      0.00  ...   23863.79   \n",
              "5      6420.73  10641.78  20544.91      0.00      0.00  ...   30187.88   \n",
              "...        ...       ...       ...       ...       ...  ...        ...   \n",
              "5396      0.00      0.00      0.00      0.00    598.42  ...       0.00   \n",
              "5397      0.00      0.00      0.00      0.00      0.00  ...       0.00   \n",
              "5398      0.00      0.00      0.00      0.00      0.00  ...       0.00   \n",
              "5399   -751.38   8999.26 -15704.96   1712.27   1115.19  ...       0.00   \n",
              "5400    669.34   -233.24    244.00      0.00     27.88  ...       0.00   \n",
              "\n",
              "      4/22/2023  4/23/2023  4/24/2023  4/25/2023  4/26/2023  4/27/2023  \\\n",
              "1          0.00        0.0   56653.36   20185.42   14739.48   14986.81   \n",
              "2          0.00        0.0   70879.69   27227.35   23704.45   50334.49   \n",
              "3          0.00        0.0   29899.24   22119.84   48042.02   43033.84   \n",
              "4          0.00        0.0   24537.67   23402.97   10848.43   29663.68   \n",
              "5          0.00        0.0   43954.74   10848.47   33575.83   33838.71   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "5396       0.00        0.0       0.00       0.00       0.00       0.00   \n",
              "5397       0.00        0.0       0.00       0.00       0.00       0.00   \n",
              "5398       0.00        0.0       0.00       0.00       0.00       0.00   \n",
              "5399       0.00        0.0       0.00       0.00       0.00       0.00   \n",
              "5400     152.88        0.0       0.00       0.00       0.00       0.00   \n",
              "\n",
              "      4/28/2023  4/29/2023  4/30/2023  \n",
              "1      39408.02        0.0       0.00  \n",
              "2      79508.11        0.0     -55.33  \n",
              "3      57073.81      -35.8       0.00  \n",
              "4      46151.86        0.0       0.00  \n",
              "5      39704.96        0.0       0.00  \n",
              "...         ...        ...        ...  \n",
              "5396       0.00        0.0       0.00  \n",
              "5397       0.00        0.0       0.00  \n",
              "5398       0.00        0.0       0.00  \n",
              "5399       0.00        0.0       0.00  \n",
              "5400     120.36        0.0       0.00  \n",
              "\n",
              "[5400 rows x 367 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32b0dc55-8374-413e-9680-446d2b38262f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Total Value</th>\n",
              "      <th>5/1/2022</th>\n",
              "      <th>5/2/2022</th>\n",
              "      <th>5/3/2022</th>\n",
              "      <th>5/4/2022</th>\n",
              "      <th>5/5/2022</th>\n",
              "      <th>5/6/2022</th>\n",
              "      <th>5/7/2022</th>\n",
              "      <th>5/8/2022</th>\n",
              "      <th>...</th>\n",
              "      <th>4/21/2023</th>\n",
              "      <th>4/22/2023</th>\n",
              "      <th>4/23/2023</th>\n",
              "      <th>4/24/2023</th>\n",
              "      <th>4/25/2023</th>\n",
              "      <th>4/26/2023</th>\n",
              "      <th>4/27/2023</th>\n",
              "      <th>4/28/2023</th>\n",
              "      <th>4/29/2023</th>\n",
              "      <th>4/30/2023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CARDINAL AG</td>\n",
              "      <td>9795245.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>87112.55</td>\n",
              "      <td>200531.83</td>\n",
              "      <td>46674.44</td>\n",
              "      <td>25938.74</td>\n",
              "      <td>14902.59</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>15143.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56653.36</td>\n",
              "      <td>20185.42</td>\n",
              "      <td>14739.48</td>\n",
              "      <td>14986.81</td>\n",
              "      <td>39408.02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WESTPHAL/MADISON</td>\n",
              "      <td>9636683.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11071.85</td>\n",
              "      <td>7058.76</td>\n",
              "      <td>15032.52</td>\n",
              "      <td>33767.46</td>\n",
              "      <td>32518.26</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>42934.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70879.69</td>\n",
              "      <td>27227.35</td>\n",
              "      <td>23704.45</td>\n",
              "      <td>50334.49</td>\n",
              "      <td>79508.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-55.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAITH/APPLETON</td>\n",
              "      <td>9263184.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>88762.71</td>\n",
              "      <td>190116.91</td>\n",
              "      <td>8995.34</td>\n",
              "      <td>5552.67</td>\n",
              "      <td>22690.98</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>42187.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29899.24</td>\n",
              "      <td>22119.84</td>\n",
              "      <td>48042.02</td>\n",
              "      <td>43033.84</td>\n",
              "      <td>57073.81</td>\n",
              "      <td>-35.8</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BW CONVERTING INC</td>\n",
              "      <td>8593581.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6268.76</td>\n",
              "      <td>20321.95</td>\n",
              "      <td>24138.10</td>\n",
              "      <td>63070.01</td>\n",
              "      <td>25113.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>23863.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24537.67</td>\n",
              "      <td>23402.97</td>\n",
              "      <td>10848.43</td>\n",
              "      <td>29663.68</td>\n",
              "      <td>46151.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PIEPER ELE/PEWAUKEE</td>\n",
              "      <td>7847637.88</td>\n",
              "      <td>2294.67</td>\n",
              "      <td>10599.71</td>\n",
              "      <td>28358.42</td>\n",
              "      <td>6420.73</td>\n",
              "      <td>10641.78</td>\n",
              "      <td>20544.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>30187.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43954.74</td>\n",
              "      <td>10848.47</td>\n",
              "      <td>33575.83</td>\n",
              "      <td>33838.71</td>\n",
              "      <td>39704.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5396</th>\n",
              "      <td>NOVOLEX</td>\n",
              "      <td>-518.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>598.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5397</th>\n",
              "      <td>WAUKESHA BEARING COR</td>\n",
              "      <td>-549.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5398</th>\n",
              "      <td>MUNICIPAL FILTRATION</td>\n",
              "      <td>-1868.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5399</th>\n",
              "      <td>PJ KAMPO ELE</td>\n",
              "      <td>-2471.54</td>\n",
              "      <td>948.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-751.38</td>\n",
              "      <td>8999.26</td>\n",
              "      <td>-15704.96</td>\n",
              "      <td>1712.27</td>\n",
              "      <td>1115.19</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5400</th>\n",
              "      <td>WES</td>\n",
              "      <td>-913928.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>669.34</td>\n",
              "      <td>-233.24</td>\n",
              "      <td>244.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>27.88</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>152.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>120.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5400 rows × 367 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b0dc55-8374-413e-9680-446d2b38262f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32b0dc55-8374-413e-9680-446d2b38262f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32b0dc55-8374-413e-9680-446d2b38262f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-32c7a5d2-a33b-4937-a297-5215499af8cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32c7a5d2-a33b-4937-a297-5215499af8cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-32c7a5d2-a33b-4937-a297-5215499af8cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1c8b9991-9ed0-4938-97e5-8424c043fe28\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1c8b9991-9ed0-4938-97e5-8424c043fe28 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Prompt user to upload files\n",
        "print(\"Please select the file(s) to upload.\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "# Display the uploaded file names\n",
        "for filename2 in uploaded2.keys():\n",
        "    print(f\"Uploaded file: {filename2}\")\n",
        "\n",
        "# Optional: Save the uploaded files locally in Colab\n",
        "for filename2, content in uploaded2.items():\n",
        "    with open(filename2, 'wb') as f:\n",
        "        f.write(content)\n",
        "        print(f\"File saved locally as: {filename2}\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv(filename2)\n",
        "df.fillna(0, inplace=True)\n",
        "df = df[1:]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Once data is read in, create augmented customer data </h1>"
      ],
      "metadata": {
        "id": "a11Ary9a8MJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "580teAIpUlVs",
        "outputId": "9c5f1a90-65b8-462d-f909-22b5186ca5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating CUST_0\n",
            "[[0.         0.87734807 0.         0.5679558  0.         0.95359116\n",
            "  0.30165746 0.         0.         0.         0.88508287 0.60552486\n",
            "  0.        ]\n",
            " [0.87734807 0.         0.5679558  0.         0.95359116 0.30165746\n",
            "  0.         0.         0.         0.88508287 0.60552486 0.\n",
            "  0.        ]\n",
            " [0.         0.5679558  0.         0.95359116 0.30165746 0.\n",
            "  0.         0.         0.88508287 0.60552486 0.         0.\n",
            "  0.        ]\n",
            " [0.5679558  0.         0.95359116 0.30165746 0.         0.\n",
            "  0.         0.88508287 0.60552486 0.         0.         0.\n",
            "  0.23646409]\n",
            " [0.         0.95359116 0.30165746 0.         0.         0.\n",
            "  0.88508287 0.60552486 0.         0.         0.         0.23646409\n",
            "  0.        ]\n",
            " [0.95359116 0.30165746 0.         0.         0.         0.88508287\n",
            "  0.60552486 0.         0.         0.         0.23646409 0.\n",
            "  1.        ]\n",
            " [0.30165746 0.         0.         0.         0.88508287 0.60552486\n",
            "  0.         0.         0.         0.23646409 0.         1.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.88508287 0.60552486 0.\n",
            "  0.         0.         0.23646409 0.         1.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.88508287 0.60552486 0.         0.\n",
            "  0.         0.23646409 0.         1.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.88508287 0.60552486 0.         0.         0.\n",
            "  0.23646409 0.         1.         0.         0.         0.\n",
            "  0.66961326]\n",
            " [0.88508287 0.60552486 0.         0.         0.         0.23646409\n",
            "  0.         1.         0.         0.         0.         0.66961326\n",
            "  0.        ]\n",
            " [0.60552486 0.         0.         0.         0.23646409 0.\n",
            "  1.         0.         0.         0.         0.66961326 0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.23646409 0.         1.\n",
            "  0.         0.         0.         0.66961326 0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.23646409 0.         1.         0.\n",
            "  0.         0.         0.66961326 0.         0.         0.\n",
            "  0.32707182]\n",
            " [0.         0.23646409 0.         1.         0.         0.\n",
            "  0.         0.66961326 0.         0.         0.         0.32707182\n",
            "  0.05745856]\n",
            " [0.23646409 0.         1.         0.         0.         0.\n",
            "  0.66961326 0.         0.         0.         0.32707182 0.05745856\n",
            "  0.        ]\n",
            " [0.         1.         0.         0.         0.         0.66961326\n",
            "  0.         0.         0.         0.32707182 0.05745856 0.\n",
            "  0.26629834]\n",
            " [1.         0.         0.         0.         0.66961326 0.\n",
            "  0.         0.         0.32707182 0.05745856 0.         0.26629834\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.66961326 0.         0.\n",
            "  0.         0.32707182 0.05745856 0.         0.26629834 0.\n",
            "  0.        ]\n",
            " [0.         0.         0.66961326 0.         0.         0.\n",
            "  0.32707182 0.05745856 0.         0.26629834 0.         0.\n",
            "  0.        ]\n",
            " [0.         0.66961326 0.         0.         0.         0.32707182\n",
            "  0.05745856 0.         0.26629834 0.         0.         0.\n",
            "  0.        ]\n",
            " [0.66961326 0.         0.         0.         0.32707182 0.05745856\n",
            "  0.         0.26629834 0.         0.         0.         0.\n",
            "  0.90607735]\n",
            " [0.         0.         0.         0.32707182 0.05745856 0.\n",
            "  0.26629834 0.         0.         0.         0.         0.90607735\n",
            "  0.        ]\n",
            " [0.         0.         0.32707182 0.05745856 0.         0.26629834\n",
            "  0.         0.         0.         0.         0.90607735 0.\n",
            "  0.        ]\n",
            " [0.         0.32707182 0.05745856 0.         0.26629834 0.\n",
            "  0.         0.         0.         0.90607735 0.         0.\n",
            "  0.18121547]\n",
            " [0.32707182 0.05745856 0.         0.26629834 0.         0.\n",
            "  0.         0.         0.90607735 0.         0.         0.18121547\n",
            "  0.03646409]\n",
            " [0.05745856 0.         0.26629834 0.         0.         0.\n",
            "  0.         0.90607735 0.         0.         0.18121547 0.03646409\n",
            "  0.8441989 ]\n",
            " [0.         0.26629834 0.         0.         0.         0.\n",
            "  0.90607735 0.         0.         0.18121547 0.03646409 0.8441989\n",
            "  0.        ]\n",
            " [0.26629834 0.         0.         0.         0.         0.90607735\n",
            "  0.         0.         0.18121547 0.03646409 0.8441989  0.\n",
            "  0.        ]]\n",
            "[[0.         0.         0.         0.         0.90607735 0.\n",
            "  0.         0.18121547 0.03646409 0.8441989  0.         0.\n",
            "  0.50276243]\n",
            " [0.         0.         0.         0.90607735 0.         0.\n",
            "  0.18121547 0.03646409 0.8441989  0.         0.         0.50276243\n",
            "  0.        ]\n",
            " [0.         0.         0.90607735 0.         0.         0.18121547\n",
            "  0.03646409 0.8441989  0.         0.         0.50276243 0.\n",
            "  0.        ]\n",
            " [0.         0.90607735 0.         0.         0.18121547 0.03646409\n",
            "  0.8441989  0.         0.         0.50276243 0.         0.\n",
            "  0.        ]\n",
            " [0.90607735 0.         0.         0.18121547 0.03646409 0.8441989\n",
            "  0.         0.         0.50276243 0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.18121547 0.03646409 0.8441989  0.\n",
            "  0.         0.50276243 0.         0.         0.         0.\n",
            "  0.40662983]\n",
            " [0.         0.18121547 0.03646409 0.8441989  0.         0.\n",
            "  0.50276243 0.         0.         0.         0.         0.40662983\n",
            "  0.7801105 ]\n",
            " [0.18121547 0.03646409 0.8441989  0.         0.         0.50276243\n",
            "  0.         0.         0.         0.         0.40662983 0.7801105\n",
            "  0.52707182]\n",
            " [0.03646409 0.8441989  0.         0.         0.50276243 0.\n",
            "  0.         0.         0.         0.40662983 0.7801105  0.52707182\n",
            "  0.        ]\n",
            " [0.8441989  0.         0.         0.50276243 0.         0.\n",
            "  0.         0.         0.40662983 0.7801105  0.52707182 0.\n",
            "  0.48839779]]\n",
            "Epoch 1/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 98997.8125\n",
            "Epoch 2/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 98988.6094\n",
            "Epoch 3/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 98979.6719\n",
            "Epoch 4/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 98971.0000\n",
            "Epoch 5/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 98962.2266\n",
            "Epoch 6/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 98953.2031\n",
            "Epoch 7/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 98944.0938\n",
            "Epoch 8/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 98934.9844\n",
            "Epoch 9/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 98925.8906\n",
            "Epoch 10/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 98916.7344\n",
            "Epoch 11/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 98907.3672\n",
            "Epoch 12/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 98897.8828\n",
            "Epoch 13/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 98888.2969\n",
            "Epoch 14/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 98878.6016\n",
            "Epoch 15/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 98868.5703\n",
            "Epoch 16/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 98858.3125\n",
            "Epoch 17/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 98847.7578\n",
            "Epoch 18/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 98836.9141\n",
            "Epoch 19/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 98825.7188\n",
            "Epoch 20/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 98814.3203\n",
            "Epoch 21/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 98802.6562\n",
            "Epoch 22/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 98790.3203\n",
            "Epoch 23/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 98777.5156\n",
            "Epoch 24/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 98764.4219\n",
            "Epoch 25/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 98750.8359\n",
            "Epoch 26/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 98736.8359\n",
            "Epoch 27/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 98722.4844\n",
            "Epoch 28/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 98707.7578\n",
            "Epoch 29/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 98692.6719\n",
            "Epoch 30/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 98677.0703\n",
            "Epoch 31/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 98661.0625\n",
            "Epoch 32/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 98644.5547\n",
            "Epoch 33/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 98627.5312\n",
            "Epoch 34/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 98609.9922\n",
            "Epoch 35/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 98591.9297\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 788669.3125\n",
            "Scaled spending: -0.007597695780787792\n",
            "False\n",
            "Generating CUST_1\n",
            "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
            "  1.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
            "  6.64202176e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
            "  6.64202176e-01]\n",
            " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.64202176e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.00000000e+00 0.00000000e+00 4.41164531e-01 6.64202176e-01\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 6.64202176e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 4.41164531e-01 2.93022442e-01 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [1.94626144e-01 6.64202176e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
            "  4.41164531e-01 2.93022442e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [1.29271108e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.29271108e-01 0.00000000e+00 4.41164531e-01\n",
            "  2.93022442e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.29271108e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  8.58621514e-02 0.00000000e+00 4.41164531e-01 2.93022442e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.29271108e-01\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.58621514e-02\n",
            "  0.00000000e+00 5.70298278e-02 2.93022442e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 5.70298278e-02 0.00000000e+00\n",
            "  5.70298278e-02]\n",
            " [0.00000000e+00 0.00000000e+00 8.58621514e-02 0.00000000e+00\n",
            "  3.78793358e-02 3.78793358e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 5.70298278e-02 0.00000000e+00 5.70298278e-02\n",
            "  3.78793358e-02]\n",
            " [0.00000000e+00 8.58621514e-02 0.00000000e+00 3.78793358e-02\n",
            "  2.51595373e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  5.70298278e-02 0.00000000e+00 2.51595373e-02 3.78793358e-02\n",
            "  2.51595373e-02]\n",
            " [1.67110194e-02 0.00000000e+00 3.78793358e-02 2.51595373e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.70298278e-02\n",
            "  0.00000000e+00 2.51595373e-02 1.67110194e-02 2.51595373e-02\n",
            "  1.67110194e-02]\n",
            " [0.00000000e+00 3.78793358e-02 2.51595373e-02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 5.70298278e-02 0.00000000e+00\n",
            "  2.51595373e-02 1.67110194e-02 1.10994955e-02 1.67110194e-02\n",
            "  1.10994955e-02]\n",
            " [7.37230904e-03 2.51595373e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 7.37230904e-03 0.00000000e+00 2.51595373e-02\n",
            "  1.67110194e-02 1.10994955e-02 7.37230904e-03 1.10994955e-02\n",
            "  0.00000000e+00]\n",
            " [4.89670371e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  4.89670371e-03 0.00000000e+00 2.51595373e-02 1.67110194e-02\n",
            "  1.10994955e-02 7.37230904e-03 4.89670371e-03 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.89670371e-03\n",
            "  0.00000000e+00 3.25240126e-03 1.67110194e-02 1.10994955e-02\n",
            "  7.37230904e-03 4.89670371e-03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 4.89670371e-03 0.00000000e+00\n",
            "  2.16025200e-03 2.16025200e-03 1.10994955e-02 7.37230904e-03\n",
            "  4.89670371e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  2.16025200e-03]\n",
            " [0.00000000e+00 4.89670371e-03 0.00000000e+00 2.16025200e-03\n",
            "  1.43484408e-03 1.43484408e-03 7.37230904e-03 4.89670371e-03\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.16025200e-03\n",
            "  1.43484408e-03]\n",
            " [9.53026560e-04 0.00000000e+00 2.16025200e-03 1.43484408e-03\n",
            "  9.53026560e-04 9.53026560e-04 4.89670371e-03 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 9.53026560e-04 1.43484408e-03\n",
            "  9.53026560e-04]\n",
            " [0.00000000e+00 2.16025200e-03 1.43484408e-03 9.53026560e-04\n",
            "  6.33002315e-04 6.33002315e-04 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 9.53026560e-04 6.33002315e-04 9.53026560e-04\n",
            "  6.33002315e-04]\n",
            " [4.20441515e-04 1.43484408e-03 9.53026560e-04 6.33002315e-04\n",
            "  4.20441515e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  9.53026560e-04 6.33002315e-04 4.20441515e-04 6.33002315e-04\n",
            "  4.20441515e-04]\n",
            " [2.79258170e-04 9.53026560e-04 6.33002315e-04 4.20441515e-04\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53026560e-04\n",
            "  6.33002315e-04 4.20441515e-04 2.79258170e-04 4.20441515e-04\n",
            "  2.79258170e-04]\n",
            " [1.85483884e-04 6.33002315e-04 4.20441515e-04 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 9.53026560e-04 6.33002315e-04\n",
            "  4.20441515e-04 2.79258170e-04 1.85483884e-04 2.79258170e-04\n",
            "  1.85483884e-04]\n",
            " [1.23198799e-04 4.20441515e-04 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.23198799e-04 6.33002315e-04 4.20441515e-04\n",
            "  2.79258170e-04 1.85483884e-04 1.23198799e-04 1.85483884e-04\n",
            "  1.23198799e-04]\n",
            " [8.18289108e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  8.18289108e-05 8.18289108e-05 4.20441515e-04 2.79258170e-04\n",
            "  1.85483884e-04 1.23198799e-04 8.18289108e-05 1.23198799e-04\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.18289108e-05\n",
            "  5.43509406e-05 5.43509406e-05 2.79258170e-04 1.85483884e-04\n",
            "  1.23198799e-04 8.18289108e-05 5.43509406e-05 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 8.18289108e-05 5.43509406e-05\n",
            "  3.61000131e-05 3.61000131e-05 1.85483884e-04 1.23198799e-04\n",
            "  8.18289108e-05 5.43509406e-05 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 8.18289108e-05 5.43509406e-05 3.61000131e-05\n",
            "  2.39777072e-05 2.39777072e-05 1.23198799e-04 8.18289108e-05\n",
            "  5.43509406e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [1.59260453e-05 5.43509406e-05 3.61000131e-05 2.39777072e-05\n",
            "  1.59260453e-05 1.59260453e-05 8.18289108e-05 5.43509406e-05\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  2.69148857e-08]\n",
            " [1.05781140e-05 3.61000131e-05 2.39777072e-05 1.59260453e-05\n",
            "  1.05781140e-05 1.05781140e-05 5.43509406e-05 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.69148857e-08\n",
            "  0.00000000e+00]]\n",
            "[[7.02600632e-06 2.39777072e-05 1.59260453e-05 1.05781140e-05\n",
            "  7.02600632e-06 7.02600632e-06 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.18738929e-08 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [4.66668869e-06 1.59260453e-05 1.05781140e-05 7.02600632e-06\n",
            "  4.66668869e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.18738929e-08 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [3.09962479e-06 1.05781140e-05 7.02600632e-06 4.66668869e-06\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.18738929e-08 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [2.05877753e-06 7.02600632e-06 4.66668869e-06 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.18738929e-08\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [1.36744452e-06 4.66668869e-06 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.18738929e-08 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [9.08259624e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.53495130e-09 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  4.88129915e-10]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.01951799e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.88129915e-10\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.01951799e-09\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.15345605e-10 0.00000000e+00\n",
            "  1.55230211e-10]\n",
            " [0.00000000e+00 0.00000000e+00 1.01951799e-09 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.15345605e-10 0.00000000e+00 1.55230211e-10\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 1.01951799e-09 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  2.15345605e-10 0.00000000e+00 6.84820634e-11 0.00000000e+00\n",
            "  0.00000000e+00]]\n",
            "Epoch 1/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 28.2556\n",
            "Epoch 2/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 28.1534\n",
            "Epoch 3/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 28.0518\n",
            "Epoch 4/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 27.9500\n",
            "Epoch 5/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 27.8537\n",
            "Epoch 6/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 27.7612\n",
            "Epoch 7/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 27.6681\n",
            "Epoch 8/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 27.5713\n",
            "Epoch 9/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 27.4702\n",
            "Epoch 10/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 27.3651\n",
            "Epoch 11/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 27.2591\n",
            "Epoch 12/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 27.1518\n",
            "Epoch 13/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 27.0437\n",
            "Epoch 14/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 26.9398\n",
            "Epoch 15/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 26.8430\n",
            "Epoch 16/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 26.7486\n",
            "Epoch 17/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 26.6592\n",
            "Epoch 18/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 26.5687\n",
            "Epoch 19/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 26.4772\n",
            "Epoch 20/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 26.3865\n",
            "Epoch 21/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 26.2954\n",
            "Epoch 22/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 26.2028\n",
            "Epoch 23/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 26.1082\n",
            "Epoch 24/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 26.0118\n",
            "Epoch 25/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 25.9170\n",
            "Epoch 26/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 25.8162\n",
            "Epoch 27/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 25.7145\n",
            "Epoch 28/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 25.6103\n",
            "Epoch 29/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 25.5041\n",
            "Epoch 30/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 25.3940\n",
            "Epoch 31/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 25.2786\n",
            "Epoch 32/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 25.1597\n",
            "Epoch 33/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 25.0390\n",
            "Epoch 34/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 24.9157\n",
            "Epoch 35/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 24.7900\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1030\n",
            "Scaled spending: -0.08245029271692364\n",
            "True\n",
            "Generating CUST_2\n",
            "[[1.         1.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         1.\n",
            "  0.        ]\n",
            " [0.5838564  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         1.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         1.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         1.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         1.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         1.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         1.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.07911687 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.04619289 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Epoch 1/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0066\n",
            "Epoch 2/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0049\n",
            "Epoch 3/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0037\n",
            "Epoch 4/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0029\n",
            "Epoch 5/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0024\n",
            "Epoch 6/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0020\n",
            "Epoch 7/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0017\n",
            "Epoch 8/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0015\n",
            "Epoch 9/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0013\n",
            "Epoch 10/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0010\n",
            "Epoch 11/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 8.4576e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.6177e-04\n",
            "Epoch 13/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.0300e-04\n",
            "Epoch 14/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.6982e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 2.6659e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 1.9310e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5258e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.2964e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.1720e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.0808e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.8725e-05\n",
            "Epoch 22/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 8.7773e-05\n",
            "Epoch 23/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.5503e-05\n",
            "Epoch 24/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.3676e-05\n",
            "Epoch 25/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.4060e-05\n",
            "Epoch 26/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.6799e-05\n",
            "Epoch 27/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.2725e-05\n",
            "Epoch 28/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 4.1887e-05\n",
            "Epoch 29/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 4.3497e-05\n",
            "Epoch 30/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.6257e-05\n",
            "Epoch 31/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.8719e-05\n",
            "Epoch 32/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 4.9743e-05\n",
            "Epoch 33/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 4.8528e-05\n",
            "Epoch 34/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 4.5066e-05\n",
            "Epoch 35/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.9947e-05\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.1985e-06\n",
            "Scaled spending: -0.08333333333333333\n",
            "False\n",
            "Generating CUST_3\n",
            "[[0.         0.91512514 0.         0.         0.86833515 0.\n",
            "  1.         0.         0.         0.         0.88139535 0.\n",
            "  0.58139535]\n",
            " [0.91512514 0.         0.         0.86833515 0.         1.\n",
            "  0.         0.         0.         0.88139535 0.         0.58139535\n",
            "  0.        ]\n",
            " [0.         0.         0.86833515 0.         1.         0.\n",
            "  0.         0.         0.88139535 0.         0.58139535 0.\n",
            "  1.        ]\n",
            " [0.         0.86833515 0.         1.         0.         0.\n",
            "  0.         0.88139535 0.         0.58139535 0.         1.\n",
            "  0.82906977]\n",
            " [0.86833515 0.         1.         0.         0.         0.\n",
            "  0.82480958 0.         0.58139535 0.         1.         0.82906977\n",
            "  0.        ]\n",
            " [0.         1.         0.         0.         0.         0.82480958\n",
            "  0.         0.58139535 0.         1.         0.82906977 0.\n",
            "  0.5872093 ]\n",
            " [1.         0.         0.         0.         0.82480958 0.\n",
            "  0.54406964 0.         1.         0.82906977 0.         0.5872093\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.82480958 0.         0.54406964\n",
            "  0.         1.         0.82906977 0.         0.5872093  0.\n",
            "  0.        ]\n",
            " [0.         0.         0.82480958 0.         0.54406964 0.\n",
            "  0.93579978 0.82906977 0.         0.5872093  0.         0.\n",
            "  0.06744186]\n",
            " [0.         0.82480958 0.         0.54406964 0.         0.93579978\n",
            "  0.77584331 0.         0.5872093  0.         0.         0.06744186\n",
            "  0.85813953]\n",
            " [0.82480958 0.         0.54406964 0.         0.93579978 0.77584331\n",
            "  0.         0.5872093  0.         0.         0.06744186 0.85813953\n",
            "  0.98604651]\n",
            " [0.         0.54406964 0.         0.93579978 0.77584331 0.\n",
            "  0.54951034 0.         0.         0.06744186 0.85813953 0.98604651\n",
            "  0.75      ]\n",
            " [0.54406964 0.         0.93579978 0.77584331 0.         0.54951034\n",
            "  0.         0.         0.06744186 0.85813953 0.98604651 0.75\n",
            "  0.        ]\n",
            " [0.         0.93579978 0.77584331 0.         0.54951034 0.\n",
            "  0.         0.06744186 0.85813953 0.98604651 0.75       0.\n",
            "  0.70813953]\n",
            " [0.93579978 0.77584331 0.         0.54951034 0.         0.\n",
            "  0.06311208 0.85813953 0.98604651 0.75       0.         0.70813953\n",
            "  0.51162791]\n",
            " [0.77584331 0.         0.54951034 0.         0.         0.06311208\n",
            "  0.80304679 0.98604651 0.75       0.         0.70813953 0.51162791\n",
            "  0.11511628]\n",
            " [0.         0.54951034 0.         0.         0.06311208 0.80304679\n",
            "  0.92274211 0.75       0.         0.70813953 0.51162791 0.11511628\n",
            "  0.        ]\n",
            " [0.54951034 0.         0.         0.06311208 0.80304679 0.92274211\n",
            "  0.70184984 0.         0.70813953 0.51162791 0.11511628 0.\n",
            "  0.        ]\n",
            " [0.         0.         0.06311208 0.80304679 0.92274211 0.70184984\n",
            "  0.         0.70813953 0.51162791 0.11511628 0.         0.\n",
            "  0.08604651]\n",
            " [0.         0.06311208 0.80304679 0.92274211 0.70184984 0.\n",
            "  0.66267682 0.51162791 0.11511628 0.         0.         0.08604651\n",
            "  0.87790698]\n",
            " [0.06311208 0.80304679 0.92274211 0.70184984 0.         0.66267682\n",
            "  0.47878128 0.11511628 0.         0.         0.08604651 0.87790698\n",
            "  0.77325581]\n",
            " [0.80304679 0.92274211 0.70184984 0.         0.66267682 0.47878128\n",
            "  0.10772579 0.         0.         0.08604651 0.87790698 0.77325581\n",
            "  0.32093023]\n",
            " [0.92274211 0.70184984 0.         0.66267682 0.47878128 0.10772579\n",
            "  0.         0.         0.08604651 0.87790698 0.77325581 0.32093023\n",
            "  0.5       ]\n",
            " [0.70184984 0.         0.66267682 0.47878128 0.10772579 0.\n",
            "  0.         0.08604651 0.87790698 0.77325581 0.32093023 0.5\n",
            "  0.        ]\n",
            " [0.         0.66267682 0.47878128 0.10772579 0.         0.\n",
            "  0.08052231 0.87790698 0.77325581 0.32093023 0.5        0.\n",
            "  0.93488372]\n",
            " [0.66267682 0.47878128 0.10772579 0.         0.         0.08052231\n",
            "  0.82154516 0.77325581 0.32093023 0.5        0.         0.93488372\n",
            "  0.69186047]\n",
            " [0.47878128 0.10772579 0.         0.         0.08052231 0.82154516\n",
            "  0.72361262 0.32093023 0.5        0.         0.93488372 0.69186047\n",
            "  0.        ]\n",
            " [0.10772579 0.         0.         0.08052231 0.82154516 0.72361262\n",
            "  0.30032644 0.5        0.         0.93488372 0.69186047 0.\n",
            "  0.66511628]\n",
            " [0.         0.         0.08052231 0.82154516 0.72361262 0.30032644\n",
            "  0.46789989 0.         0.93488372 0.69186047 0.         0.66511628\n",
            "  0.        ]]\n",
            "[[0.         0.08052231 0.82154516 0.72361262 0.30032644 0.46789989\n",
            "  0.         0.93488372 0.69186047 0.         0.66511628 0.\n",
            "  0.        ]\n",
            " [0.08052231 0.82154516 0.72361262 0.30032644 0.46789989 0.\n",
            "  0.87486398 0.69186047 0.         0.66511628 0.         0.\n",
            "  0.        ]\n",
            " [0.82154516 0.72361262 0.30032644 0.46789989 0.         0.87486398\n",
            "  0.64744287 0.         0.66511628 0.         0.         0.\n",
            "  0.        ]\n",
            " [0.72361262 0.30032644 0.46789989 0.         0.87486398 0.64744287\n",
            "  0.         0.66511628 0.         0.         0.         0.\n",
            "  0.49767442]\n",
            " [0.30032644 0.46789989 0.         0.87486398 0.64744287 0.\n",
            "  0.62241567 0.         0.         0.         0.         0.49767442\n",
            "  1.13604651]\n",
            " [0.46789989 0.         0.87486398 0.64744287 0.         0.62241567\n",
            "  0.         0.         0.         0.         0.49767442 1.13604651\n",
            "  0.        ]\n",
            " [0.         0.87486398 0.64744287 0.         0.62241567 0.\n",
            "  0.         0.         0.         0.49767442 1.13604651 0.\n",
            "  0.65813953]\n",
            " [0.87486398 0.64744287 0.         0.62241567 0.         0.\n",
            "  0.         0.         0.49767442 1.13604651 0.         0.65813953\n",
            "  0.        ]\n",
            " [0.64744287 0.         0.62241567 0.         0.         0.\n",
            "  0.         0.49767442 1.13604651 0.         0.65813953 0.\n",
            "  0.36162791]\n",
            " [0.         0.62241567 0.         0.         0.         0.\n",
            "  0.46572361 1.13604651 0.         0.65813953 0.         0.36162791\n",
            "  0.        ]]\n",
            "Epoch 1/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 219734.4844\n",
            "Epoch 2/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 219704.6875\n",
            "Epoch 3/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 219675.2656\n",
            "Epoch 4/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 219645.9062\n",
            "Epoch 5/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 219616.6875\n",
            "Epoch 6/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 219587.3125\n",
            "Epoch 7/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 219558.0000\n",
            "Epoch 8/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 219528.3125\n",
            "Epoch 9/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 219498.9688\n",
            "Epoch 10/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 219470.6875\n",
            "Epoch 11/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 219443.6875\n",
            "Epoch 12/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 219416.4062\n",
            "Epoch 13/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 219388.8594\n",
            "Epoch 14/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 219361.2031\n",
            "Epoch 15/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 219333.2188\n",
            "Epoch 16/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 219305.4844\n",
            "Epoch 17/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 219277.5938\n",
            "Epoch 18/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 219249.4531\n",
            "Epoch 19/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 219220.9375\n",
            "Epoch 20/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 219191.6250\n",
            "Epoch 21/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 219161.3438\n",
            "Epoch 22/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 219130.2812\n",
            "Epoch 23/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 219098.1250\n",
            "Epoch 24/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 219064.5156\n",
            "Epoch 25/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 219029.5469\n",
            "Epoch 26/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 218993.3125\n",
            "Epoch 27/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 218955.8438\n",
            "Epoch 28/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 218917.2031\n",
            "Epoch 29/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 218876.6094\n",
            "Epoch 30/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 218834.0000\n",
            "Epoch 31/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 218789.4531\n",
            "Epoch 32/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 218742.5469\n",
            "Epoch 33/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 218693.7812\n",
            "Epoch 34/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 218642.8281\n",
            "Epoch 35/35\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 218589.9375\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 749922.1875\n",
            "Scaled spending: -0.005459114715323534\n",
            "False\n",
            "Generating CUST_4\n"
          ]
        }
      ],
      "source": [
        "def generate_augmented(churned):\n",
        "  rand = random.randint(0,len(df)-1)\n",
        "  row = df.iloc[rand][2:]\n",
        "  row.index = pd.to_datetime(row.index)\n",
        "  weekly_sales = row.resample('W').sum()\n",
        "  weekly_sales = (weekly_sales - weekly_sales.min()) / (weekly_sales.max() - weekly_sales.min()) * 100\n",
        "  weeks = 52  # 12 months of weekly data\n",
        "  spending = np.zeros(52)\n",
        "  start_spend = np.random.uniform(0, 100)\n",
        "\n",
        "\n",
        "  if churned:\n",
        "      # Simulate spending decrease over time, leading to 0\n",
        "      drop_point = np.random.randint(15, 40)  # Random point where spending drops\n",
        "      decay = np.random.uniform(0.6, 0.95)  # How fast spending drops\n",
        "      for i in range(drop_point):\n",
        "        ggg = random.random() < 0.3\n",
        "        if ggg:\n",
        "          spending[i] = 0\n",
        "        else:\n",
        "          spending[i] = weekly_sales.iloc[i] + np.random.normal(0, start_spend * 0.1)\n",
        "\n",
        "      for i in range(drop_point, weeks):\n",
        "        #introduce 0 sell weeks\n",
        "        no_sell = random.random() < 0.6\n",
        "        if no_sell:\n",
        "          spending[i] = 0\n",
        "        else:\n",
        "          no_sell = random.random() < 0.77\n",
        "          if no_sell:\n",
        "            if i < len(weekly_sales):\n",
        "                spending[i] = weekly_sales.iloc[i]\n",
        "            else:\n",
        "                spending[i] = 0  # Handle missing weeks gracefully\n",
        "\n",
        "          else:\n",
        "            try:\n",
        "              spending[i] = spending[i-1] * (decay ** (i * 2))\n",
        "            except:\n",
        "              spending[i] = start_spend * decay ** (i * 2)\n",
        "\n",
        "  else:\n",
        "    for i in range(52):\n",
        "\n",
        "      random_drop = random.random() < 0.05\n",
        "      if random_drop:\n",
        "        spending[i] = 0\n",
        "      else:\n",
        "        spending[i] = row.iloc[i] + np.random.normal(0, start_spend * 0.1)\n",
        "\n",
        "  return spending\n",
        "\n",
        "\n",
        "def untouched_data(churned):\n",
        "  rand = random.randint(0,len(df)-1)\n",
        "  row = df.iloc[rand][2:]\n",
        "  row.index = pd.to_datetime(row.index)\n",
        "  weeks = 52\n",
        "  weekly_sales = row.resample('W').sum()\n",
        "  weekly_sales = (weekly_sales - weekly_sales.min()) / (weekly_sales.max() - weekly_sales.min()) * 100\n",
        "  spending = np.zeros(weeks)\n",
        "  for i in range(weeks):\n",
        "    spending[i] = weekly_sales.iloc[i]\n",
        "\n",
        "  return spending\n",
        "\n",
        "\n",
        "def low_spend_customer(churned):\n",
        "  weeks = 52\n",
        "  spending = np.zeros(weeks)\n",
        "  for i in range(weeks):\n",
        "    if churned:\n",
        "      spend = random.random() < 0.2\n",
        "      if spend:\n",
        "        spending[i] = random.randint(10,1000)\n",
        "    else:\n",
        "      spend = random.random() < 0.5\n",
        "      if spend:\n",
        "        spending[i] = random.randint(10,1000)\n",
        "\n",
        "  return spending\n",
        "\n",
        "\n",
        "\n",
        "def generate_churn(churned):\n",
        "    weeks = 52  # 12 months of weekly data\n",
        "    spending = np.zeros(weeks)\n",
        "\n",
        "    if churned:\n",
        "        # Simulate spending decrease over time, leading to 0\n",
        "        start_spend = np.random.uniform(1, 100)\n",
        "        drop_point = np.random.randint(25, 40)  # Random point where spending drops\n",
        "        decay = np.random.uniform(0.4, 0.95)  # How fast spending drops\n",
        "        for i in range(drop_point):\n",
        "            spending[i] = start_spend * (decay ** i)\n",
        "        for i in range(drop_point, weeks):\n",
        "            spending[i] = 0  # No purchases after drop\n",
        "    else:\n",
        "        # Regular spending pattern with some fluctuations\n",
        "        avg_spend = np.random.uniform(1, 100)\n",
        "        for i in range(weeks):\n",
        "          \"\"\" Implement random slowdowns \"\"\"\n",
        "          if random.random() < 0.25:\n",
        "            spending[i] = 0\n",
        "          else:\n",
        "            if random.random() < 0.2:\n",
        "              decay = np.random.uniform(0.4, 0.95)\n",
        "              spending[i] = max(0, avg_spend + np.random.normal(0, avg_spend * 0.2) - decay)\n",
        "            else:\n",
        "              spending[i] = max(0, avg_spend + np.random.normal(0, avg_spend * 0.2))  # Add noise\n",
        "\n",
        "    return spending\n",
        "\n",
        "\n",
        "def generate_at_risk(churned):\n",
        "    weeks = 52  # 12 months of weekly data\n",
        "    spending = np.zeros(weeks)\n",
        "\n",
        "    if churned:\n",
        "        # Simulate spending decrease over time, leading to 0\n",
        "        start_spend = np.random.uniform(100, 15000)\n",
        "        drop_point = np.random.randint(25, 40)  # Random point where spending drops\n",
        "        decay = np.random.uniform(0.6, 0.95)  # How fast spending drops\n",
        "        for i in range(drop_point):\n",
        "          random_slowdown = random.random() < 0.33\n",
        "          if random_slowdown:\n",
        "            spending[i] = 0\n",
        "            #50% chance to set previous week to 0\n",
        "            if i > 1:\n",
        "              jit = random.random() < 0.5\n",
        "              if jit:\n",
        "                spending[i-1] = 0\n",
        "          else:\n",
        "            spending[i] = start_spend * (decay ** i)\n",
        "\n",
        "        for i in range(drop_point, weeks):\n",
        "          #introduce 0 sell weeks\n",
        "          no_sell = random.random() < 0.70\n",
        "          if no_sell:\n",
        "            spending[i] = 0\n",
        "          else:\n",
        "            no_sell = random.random() < 0.77\n",
        "            if no_sell:\n",
        "              spending[i] = start_spend * (decay ** (i * 1.4))\n",
        "            else:\n",
        "              try:\n",
        "                spending[i] = spending[i-1] * (decay ** (i * 2))\n",
        "              except:\n",
        "                spending[i] = start_spend * decay ** (i * 2)\n",
        "\n",
        "    else:\n",
        "        # Regular spending pattern with some fluctuations\n",
        "        avg_spend = np.random.uniform(1, 100)\n",
        "        for i in range(weeks):\n",
        "            spending[i] = max(0, avg_spend + np.random.normal(0, avg_spend * 0.1))  # Add noise\n",
        "\n",
        "    return spending\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of customers\n",
        "n_customers = 100\n",
        "\n",
        "# Generate random customer IDs\n",
        "customer_ids = [f\"CUST_{i}\" for i in range(n_customers)]\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#generate synthetic dataset\n",
        "data = []\n",
        "\n",
        "for customer in customer_ids:\n",
        "  print(f\"Generating {customer}\")\n",
        "  #set churn_state to true 33% of the time\n",
        "  churned = random.random() < 0.33\n",
        "  generator_seed = random.random()\n",
        "  if generator_seed < 0.2: # 30% chance to use real customer data\n",
        "    churned = False\n",
        "    #set flag to false, since customer is very likely not going to be at risk\n",
        "    c = untouched_data(churned)\n",
        "  else:\n",
        "    if generator_seed < 0.75:\n",
        "      c = low_spend_customer(churned)\n",
        "    else:\n",
        "      if generator_seed < 0.85: #25% chance to use augmented customer data\n",
        "        c = generate_augmented(churned)\n",
        "      else:\n",
        "        if generator_seed < 0.95: #45% chance to create synthetic at risk data\n",
        "          c = generate_at_risk(churned)\n",
        "        else:\n",
        "          c = generate_churn(churned) #10% chance to create synthetic churn data\n",
        "\n",
        "  last_purchase_week = np.argmax(c[::-1] > 0)\n",
        "  total_spend = np.sum(c)\n",
        "  average_monthly_spend = total_spend / 12\n",
        "  spending_trend = np.mean(c[-12:]) - np.mean(c[:12])  # First quarter vs last quarter spending\n",
        "\n",
        "  total_0_weeks = 0\n",
        "  for i in range(len(c)):\n",
        "    if c[i] == 0:\n",
        "      total_0_weeks += 1\n",
        "\n",
        "  weeks = []\n",
        "  for i in range(len(c) - 3):\n",
        "      ind = i + 3\n",
        "      d = c[ind]  # True value for next week\n",
        "      try:\n",
        "          # Fit ARIMA model to predict the next value (week)\n",
        "          model = ARIMA(c[max(0, ind-12):ind], order=(4, 0, 1))\n",
        "          fitted_model = model.fit()\n",
        "          ARIMA_pred = fitted_model.forecast(steps=1)[0]  # Forecast the next value (next week)\n",
        "      except:\n",
        "          ARIMA_pred = 1  # Default value if ARIMA fails (you may adjust this)\n",
        "\n",
        "      try:\n",
        "          # Check if the true value is 30% outside the predicted value\n",
        "          if ARIMA_pred != 0 and (d < ARIMA_pred * 0.3):\n",
        "              weeks.append(1)  # Mark as abnormal week\n",
        "          else:\n",
        "              weeks.append(0)  # Normal week\n",
        "      except:\n",
        "          weeks.append(0)  # Handle any errors gracefully\n",
        "\n",
        "    # Calculate the total number of abnormal weeks\n",
        "  total_abnormal_weeks = sum(weeks)\n",
        "\n",
        "  \"\"\" Fourier Analysis \"\"\"\n",
        "\n",
        "  N = len(c)\n",
        "\n",
        "  # Number of weeks in each quarter (since we're dealing with 52 weeks of data, each quarter is 13 weeks)\n",
        "  quarter_length = 13\n",
        "\n",
        "  # Initialize list to store peak amplitudes for each quarter\n",
        "  peak_amplitudes = []\n",
        "  peak_frequencies = []\n",
        "\n",
        "  for i in range(4):\n",
        "      # Define the start and end of each quarter\n",
        "      start_idx = i * quarter_length\n",
        "      end_idx = start_idx + quarter_length\n",
        "\n",
        "      # Slice the data to get the current quarter\n",
        "      quarter_data = c[start_idx:end_idx]\n",
        "\n",
        "      # Perform Fourier Transform on the current quarter's data\n",
        "      fourier_y = fft(quarter_data)\n",
        "      fourier_x = fftfreq(len(quarter_data), 1.0)[:len(quarter_data) // 2]  # Frequency axis for this quarter\n",
        "\n",
        "      # Calculate the amplitudes and peak frequency for this quarter\n",
        "      amplitudes = 2.0 / len(quarter_data) * np.abs(fourier_y[:len(quarter_data) // 2])\n",
        "      peak_freq = fourier_x[np.argmax(amplitudes)]  # Peak frequency\n",
        "      peak_amplitude = np.max(amplitudes)  # Peak amplitude\n",
        "\n",
        "      # Store the peak amplitude for this quarter\n",
        "      peak_amplitudes.append(peak_amplitude)\n",
        "      peak_frequencies.append(peak_freq)\n",
        "\n",
        "  # Now, peak_amplitudes contains the peak amplitude for each of the four quarters\n",
        "\n",
        "  #peak_amplitudes = [entry / total_spend for entry in peak_amplitudes]\n",
        "  q1_f, q2_f, q3_f, q4_f = peak_amplitudes\n",
        "  q1_pf, q2_pf, q3_pf, q4_pf = peak_frequencies\n",
        "\n",
        "  try:\n",
        "\n",
        "    net_fourier_diff = (q4_f - q1_f) / np.mean(peak_amplitudes)\n",
        "\n",
        "    net_freq_diff = (q4_pf - q1_pf) / np.mean(peak_amplitudes)\n",
        "\n",
        "  except:\n",
        "    net_fourier_diff = 0\n",
        "    net_freq_diff = 0\n",
        "\n",
        "  avg_fourier_diff = q4_f - np.mean(peak_amplitudes)\n",
        "\n",
        "  avg_freq_diff = q4_pf - np.mean(peak_frequencies)\n",
        "\n",
        "  \"\"\" develop tensorflow flag system \"\"\"\n",
        "\n",
        "  from tensorflow.keras.layers import Dense, LSTM\n",
        "  from tensorflow.keras.models import Sequential\n",
        "\n",
        "  window_size = 13  # Use the previous quarter (13 weeks) as the input window\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  # Create sliding window features\n",
        "  for i in range(window_size, len(c)):\n",
        "      X.append(c[i - window_size:i])  # Last quarter's data\n",
        "      y.append(c[i])  # Target is this week's sales\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  # Manual time-based train-test split (75% train, 25% test)\n",
        "  split_index = int(len(X) * 0.75)\n",
        "\n",
        "  X_train, X_test = X[:split_index], X[split_index:]\n",
        "  y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "  # Print shapes to verify\n",
        "  \"\"\"\n",
        "  print(\"X_train shape:\", X_train.shape)\n",
        "  print(\"y_train shape:\", y_train.shape)\n",
        "  print(\"X_test shape:\", X_test.shape)\n",
        "  print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "  \"\"\"\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "  # Fit the scaler to your training data and transform it\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "  # Apply the same transformation to your test data\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # Check the results (scaled data between 0 and 1)\n",
        "  print(X_train_scaled)\n",
        "  print(X_test_scaled)\n",
        "\n",
        "\n",
        "  # Build a simple LSTM model for financial prediction\n",
        "  model = Sequential([\n",
        "    Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),  # Input layer\n",
        "    Dense(32, activation='relu'),  # Hidden layer\n",
        "    Dense(1)  # Output layer (1 value: predicted weekly sales)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(X_train_scaled, y_train, epochs=35, batch_size=32)\n",
        "  loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "  tensorflow_flag = (loss < 1)\n",
        "\n",
        "  low_spending = (total_abnormal_weeks > 13)\n",
        "\n",
        "  #manually set churn status if customer meets certain requirements\n",
        "\n",
        "  #======================= NEW LOGIC FOR SETTING STATE =====================\n",
        "\n",
        "  state = \"NEUTRAL\"\n",
        "\n",
        "  # get scaled spending\n",
        "\n",
        "  scaled_av_spend = spending_trend / total_spend\n",
        "  print(f\"Scaled spending: {scaled_av_spend}\")\n",
        "\n",
        "  if total_0_weeks > random.randint(30,40):\n",
        "    state = \"AT RISK\"\n",
        "\n",
        "  if last_purchase_week > random.randint(16, 25):\n",
        "    state = \"AT RISK\"\n",
        "\n",
        "  if net_fourier_diff < -2:\n",
        "    stop_point = random.randint(-60, -30)\n",
        "    if spending_trend < stop_point:\n",
        "      state = \"AT RISK\"\n",
        "\n",
        "  if net_fourier_diff > 2:\n",
        "    if spending_trend > random.uniform(1.2, 2.5):\n",
        "      state = \"OVERPERFORMING\"\n",
        "\n",
        "  print(churned)\n",
        "\n",
        "  data.append([customer, total_spend, last_purchase_week, total_0_weeks,\n",
        "               average_monthly_spend, spending_trend, total_abnormal_weeks,\n",
        "              q1_f, q4_f, net_fourier_diff, avg_fourier_diff,\n",
        "               loss, tensorflow_flag, low_spending, state])\n",
        "\n",
        "columns = ['Customer ID', 'Total Spend', 'Weeks Since Last Purchase', 'Amount of 0 Sell Weeks','Average Spending Per Month','Spending Trend',\n",
        "           'Total Abnormal Weeks', 'Q1 Amplitude', 'Q4 Amplitude', 'Net Fourier Difference',\n",
        "           'Net Fourier Difference From Average',\n",
        "           'TensorFlow Loss','TensorFlow Flag','Low Spending Flag','Churn State']\n",
        "\n",
        "at_risk_df = pd.DataFrame(data=data, columns=columns)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "at_risk_df.to_csv('synthetic_risk_data.csv', index=False)\n",
        "files.download('synthetic_risk_data.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}